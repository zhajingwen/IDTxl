#!/usr/bin/env python3
"""
åŠ å¯†è´§å¸å¸‚åœºç½‘ç»œåˆ†æç³»ç»Ÿ - æ— Javaä¾èµ–ç‰ˆæœ¬
åŸºäºIDTxlçš„PythonåŸç”Ÿä¼°è®¡å™¨ï¼Œæ— éœ€Javaç¯å¢ƒ

åŠŸèƒ½ï¼š
1. ä»Hyperliquid APIè·å–åŠ å¯†è´§å¸ä»·æ ¼æ•°æ®
2. ä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨è¿›è¡Œç½‘ç»œåˆ†æ
3. è¯†åˆ«é«˜åº¦å…³è”çš„èµ„äº§ç»„åˆ
4. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import os
import sys
import time
import json
import logging
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# IDTxl imports - åªä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨
from idtxl.data import Data
from idtxl.multivariate_te import MultivariateTE
from idtxl.multivariate_mi import MultivariateMI
from idtxl.visualise_graph import plot_network

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('crypto_network_analysis_no_java.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class HyperliquidDataFetcher:
    """Hyperliquid APIæ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.base_url = "https://api.hyperliquid.xyz"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'CryptoNetworkAnalysis/1.0',
            'Accept': 'application/json'
        })
    
    def get_all_tokens(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å·²ä¸Šçº¿çš„ä»£å¸ä¿¡æ¯"""
        try:
            url = f"{self.base_url}/info"
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            tokens = data.get('universe', [])
            
            logger.info(f"æˆåŠŸè·å– {len(tokens)} ä¸ªä»£å¸ä¿¡æ¯")
            return tokens
            
        except Exception as e:
            logger.error(f"è·å–ä»£å¸ä¿¡æ¯å¤±è´¥: {e}")
            return []
    
    def get_token_prices(self, tokens: List[str], hours: int = 24) -> pd.DataFrame:
        """è·å–ä»£å¸ä»·æ ¼æ•°æ®"""
        try:
            # è·å–å†å²ä»·æ ¼æ•°æ®
            end_time = int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
            start_time = end_time - (hours * 60 * 60 * 1000)
            
            url = f"{self.base_url}/info"
            params = {
                'type': 'candleSnapshot',
                'coin': ','.join(tokens),
                'interval': '1h',  # 1å°æ—¶Kçº¿
                'startTime': start_time,
                'endTime': end_time
            }
            
            response = self.session.get(url, params=params, timeout=60)
            response.raise_for_status()
            
            data = response.json()
            
            # å¤„ç†ä»·æ ¼æ•°æ®
            price_data = {}
            for token_data in data:
                coin = token_data['coin']
                candles = token_data['candles']
                
                if candles:
                    df = pd.DataFrame(candles)
                    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')
                    df['price'] = df['c'].astype(float)  # æ”¶ç›˜ä»·
                    df = df.set_index('timestamp')
                    price_data[coin] = df['price']
            
            # åˆå¹¶æ‰€æœ‰ä»£å¸ä»·æ ¼æ•°æ®
            price_df = pd.DataFrame(price_data)
            price_df = price_df.dropna()  # åˆ é™¤ç¼ºå¤±å€¼
            
            logger.info(f"æˆåŠŸè·å– {len(price_df.columns)} ä¸ªä»£å¸çš„ {len(price_df)} å°æ—¶ä»·æ ¼æ•°æ®")
            return price_df
            
        except Exception as e:
            logger.error(f"è·å–ä»·æ ¼æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()


class CryptoNetworkAnalyzerNoJava:
    """åŠ å¯†è´§å¸ç½‘ç»œåˆ†æå™¨ - æ— Javaä¾èµ–ç‰ˆæœ¬"""
    
    def __init__(self, config: Dict = None):
        self.config = config or self._default_config()
        self.data_fetcher = HyperliquidDataFetcher()
        self.price_data = None
        self.network_results = None
        
    def _default_config(self) -> Dict:
        """é»˜è®¤é…ç½® - ä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨"""
        return {
            'min_price': 0.001,  # æœ€å°ä»·æ ¼è¿‡æ»¤
            'min_volume': 10000,  # æœ€å°äº¤æ˜“é‡è¿‡æ»¤
            'max_tokens': 30,  # æœ€å¤§åˆ†æä»£å¸æ•°é‡ï¼ˆå‡å°‘ä»¥æé«˜æ€§èƒ½ï¼‰
            'time_hours': 72,  # åˆ†ææ—¶é—´çª—å£ï¼ˆ3å¤©ï¼Œå‡å°‘ä»¥æé«˜æ€§èƒ½ï¼‰
            'cmi_estimator': 'PythonKraskovCMI',  # ä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨
            'max_lag_sources': 6,  # å‡å°‘æ»åä»¥æé«˜æ€§èƒ½
            'min_lag_sources': 1,
            'max_lag_target': 3,
            'tau_sources': 1,
            'tau_target': 1,
            'n_perm_max_stat': 50,  # å‡å°‘ç½®æ¢æ¬¡æ•°ä»¥æé«˜é€Ÿåº¦
            'n_perm_min_stat': 50,
            'n_perm_omnibus': 100,
            'fdr_alpha': 0.05,  # FDRæ˜¾è‘—æ€§æ°´å¹³
            'correlation_threshold': 0.6,  # é™ä½ç›¸å…³æ€§é˜ˆå€¼
            'te_threshold': 0.05,  # é™ä½ä¼ é€’ç†µé˜ˆå€¼
            'kraskov_k': 4,  # Kraskovä¼°è®¡å™¨å‚æ•°
            'num_threads': 'USE_ALL',  # ä½¿ç”¨æ‰€æœ‰å¯ç”¨çº¿ç¨‹
        }
    
    def fetch_and_preprocess_data(self) -> bool:
        """è·å–å¹¶é¢„å¤„ç†æ•°æ®"""
        try:
            logger.info("å¼€å§‹è·å–åŠ å¯†è´§å¸æ•°æ®...")
            
            # è·å–æ‰€æœ‰ä»£å¸
            tokens_info = self.data_fetcher.get_all_tokens()
            if not tokens_info:
                logger.error("æ— æ³•è·å–ä»£å¸ä¿¡æ¯")
                return False
            
            # è¿‡æ»¤ä»£å¸
            filtered_tokens = self._filter_tokens(tokens_info)
            if not filtered_tokens:
                logger.error("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ä»£å¸")
                return False
            
            logger.info(f"é€‰æ‹© {len(filtered_tokens)} ä¸ªä»£å¸è¿›è¡Œåˆ†æ")
            
            # è·å–ä»·æ ¼æ•°æ®
            self.price_data = self.data_fetcher.get_token_prices(
                filtered_tokens, 
                self.config['time_hours']
            )
            
            if self.price_data.empty:
                logger.error("æ— æ³•è·å–ä»·æ ¼æ•°æ®")
                return False
            
            # æ•°æ®é¢„å¤„ç†
            self._preprocess_data()
            
            logger.info(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œæœ€ç»ˆæ•°æ®å½¢çŠ¶: {self.price_data.shape}")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®è·å–å’Œé¢„å¤„ç†å¤±è´¥: {e}")
            return False
    
    def _filter_tokens(self, tokens_info: List[Dict]) -> List[str]:
        """è¿‡æ»¤ä»£å¸"""
        filtered = []
        
        for token in tokens_info:
            # åŸºæœ¬è¿‡æ»¤æ¡ä»¶
            if (token.get('maxLeverage', 0) > 0 and  # æœ‰æ æ†
                token.get('onlyIsolated', False) == False and  # æ”¯æŒäº¤å‰ä¿è¯é‡‘
                len(token.get('name', '')) > 0):  # æœ‰åç§°
                
                filtered.append(token['name'])
                
                if len(filtered) >= self.config['max_tokens']:
                    break
        
        return filtered
    
    def _preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        # è®¡ç®—æ”¶ç›Šç‡
        returns = self.price_data.pct_change().dropna()
        
        # ç§»é™¤å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡3ä¸ªæ ‡å‡†å·®ï¼‰
        returns = returns[np.abs(returns) < 3 * returns.std()]
        
        # æ ‡å‡†åŒ–æ•°æ®
        returns = (returns - returns.mean()) / returns.std()
        
        self.price_data = returns
        
        logger.info("æ•°æ®é¢„å¤„ç†å®Œæˆï¼šè®¡ç®—æ”¶ç›Šç‡ã€ç§»é™¤å¼‚å¸¸å€¼ã€æ ‡å‡†åŒ–")
    
    def analyze_network(self) -> bool:
        """æ‰§è¡Œç½‘ç»œåˆ†æ - ä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨"""
        try:
            logger.info("å¼€å§‹ç½‘ç»œåˆ†æï¼ˆä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨ï¼‰...")
            
            # å‡†å¤‡IDTxlæ•°æ®æ ¼å¼
            data_array = self.price_data.values.T  # è½¬ç½®ä¸º(processes, samples)æ ¼å¼
            data = Data(data_array, dim_order='ps')
            
            # é…ç½®åˆ†æå‚æ•° - ä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨
            settings = {
                'cmi_estimator': self.config['cmi_estimator'],
                'max_lag_sources': self.config['max_lag_sources'],
                'min_lag_sources': self.config['min_lag_sources'],
                'max_lag_target': self.config['max_lag_target'],
                'tau_sources': self.config['tau_sources'],
                'tau_target': self.config['tau_target'],
                'n_perm_max_stat': self.config['n_perm_max_stat'],
                'n_perm_min_stat': self.config['n_perm_min_stat'],
                'n_perm_omnibus': self.config['n_perm_omnibus'],
                'fdr_alpha': self.config['fdr_alpha'],
                'kraskov_k': self.config['kraskov_k'],
                'num_threads': self.config['num_threads'],
            }
            
            # æ‰§è¡Œå¤šå…ƒä¼ é€’ç†µåˆ†æ
            logger.info("æ‰§è¡Œå¤šå…ƒä¼ é€’ç†µåˆ†æ...")
            network_analysis = MultivariateTE()
            self.network_results = network_analysis.analyse_network(
                settings=settings, 
                data=data
            )
            
            logger.info("ç½‘ç»œåˆ†æå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"ç½‘ç»œåˆ†æå¤±è´¥: {e}")
            return False
    
    def analyze_correlation_network(self) -> Dict:
        """åŸºäºç›¸å…³æ€§çš„ç½‘ç»œåˆ†æ - ä½œä¸ºä¼ é€’ç†µçš„è¡¥å……"""
        try:
            logger.info("æ‰§è¡Œç›¸å…³æ€§ç½‘ç»œåˆ†æ...")
            
            # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
            correlation_matrix = self.price_data.corr()
            
            # è¯†åˆ«é«˜åº¦ç›¸å…³çš„èµ„äº§å¯¹
            highly_correlated = []
            for i in range(len(correlation_matrix.columns)):
                for j in range(i+1, len(correlation_matrix.columns)):
                    corr = correlation_matrix.iloc[i, j]
                    if abs(corr) >= self.config['correlation_threshold']:
                        asset1 = correlation_matrix.columns[i]
                        asset2 = correlation_matrix.columns[j]
                        highly_correlated.append({
                            'asset1': asset1,
                            'asset2': asset2,
                            'correlation': corr,
                            'abs_correlation': abs(corr)
                        })
            
            # æŒ‰ç›¸å…³æ€§å¼ºåº¦æ’åº
            highly_correlated.sort(key=lambda x: x['abs_correlation'], reverse=True)
            
            # åŸºäºç›¸å…³æ€§æ„å»ºç½‘ç»œ
            correlation_network = {
                'correlation_matrix': correlation_matrix,
                'highly_correlated_pairs': highly_correlated,
                'network_density': len(highly_correlated) / (len(correlation_matrix.columns) * (len(correlation_matrix.columns) - 1) / 2)
            }
            
            logger.info(f"ç›¸å…³æ€§åˆ†æå®Œæˆï¼šå‘ç° {len(highly_correlated)} ä¸ªé«˜ç›¸å…³å¯¹")
            return correlation_network
            
        except Exception as e:
            logger.error(f"ç›¸å…³æ€§ç½‘ç»œåˆ†æå¤±è´¥: {e}")
            return {}
    
    def identify_highly_correlated_assets(self) -> Dict:
        """è¯†åˆ«é«˜åº¦å…³è”çš„èµ„äº§ç»„åˆ"""
        try:
            logger.info("è¯†åˆ«é«˜åº¦å…³è”çš„èµ„äº§ç»„åˆ...")
            
            # è·å–ä¼ é€’ç†µç½‘ç»œç»“æœ
            te_connections = []
            if self.network_results is not None:
                edge_list = self.network_results.get_edge_list()
                for edge in edge_list:
                    if edge[2] >= self.config['te_threshold']:  # ä¼ é€’ç†µé˜ˆå€¼
                        te_connections.append({
                            'source': self.price_data.columns[edge[0]],
                            'target': self.price_data.columns[edge[1]],
                            'transfer_entropy': edge[2],
                            'p_value': edge[3] if len(edge) > 3 else None
                        })
                
                # æŒ‰ä¼ é€’ç†µå¼ºåº¦æ’åº
                te_connections.sort(key=lambda x: x['transfer_entropy'], reverse=True)
            
            # æ‰§è¡Œç›¸å…³æ€§åˆ†æ
            correlation_network = self.analyze_correlation_network()
            highly_correlated = correlation_network.get('highly_correlated_pairs', [])
            
            # è¯†åˆ«èµ„äº§ç»„åˆ
            asset_combinations = self._find_asset_combinations(
                highly_correlated, 
                te_connections
            )
            
            results = {
                'correlation_pairs': highly_correlated,
                'te_connections': te_connections,
                'asset_combinations': asset_combinations,
                'correlation_network': correlation_network,
                'summary': {
                    'total_assets': len(self.price_data.columns),
                    'highly_correlated_pairs': len(highly_correlated),
                    'te_connections': len(te_connections),
                    'asset_combinations': len(asset_combinations),
                    'network_density': correlation_network.get('network_density', 0)
                }
            }
            
            logger.info(f"è¯†åˆ«å®Œæˆï¼š{len(highly_correlated)}ä¸ªé«˜ç›¸å…³å¯¹ï¼Œ{len(te_connections)}ä¸ªTEè¿æ¥ï¼Œ{len(asset_combinations)}ä¸ªèµ„äº§ç»„åˆ")
            return results
            
        except Exception as e:
            logger.error(f"è¯†åˆ«é«˜åº¦å…³è”èµ„äº§å¤±è´¥: {e}")
            return {}
    
    def _find_asset_combinations(self, correlated_pairs: List, te_connections: List) -> List:
        """å¯»æ‰¾èµ„äº§ç»„åˆ"""
        combinations = []
        
        # åŸºäºç›¸å…³æ€§çš„ç»„åˆ
        asset_groups = {}
        for pair in correlated_pairs:
            asset1, asset2 = pair['asset1'], pair['asset2']
            
            # å¯»æ‰¾ç°æœ‰ç»„
            found_group = None
            for group_id, group in asset_groups.items():
                if asset1 in group or asset2 in group:
                    found_group = group_id
                    break
            
            if found_group is not None:
                asset_groups[found_group].update([asset1, asset2])
            else:
                new_group_id = len(asset_groups)
                asset_groups[new_group_id] = {asset1, asset2}
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        for group_id, group in asset_groups.items():
            if len(group) >= 2:  # è‡³å°‘2ä¸ªèµ„äº§
                combinations.append({
                    'type': 'correlation_based',
                    'assets': list(group),
                    'size': len(group),
                    'strength': 'high' if len(group) >= 3 else 'medium'
                })
        
        # åŸºäºä¼ é€’ç†µçš„ç»„åˆ
        te_groups = {}
        for conn in te_connections:
            source, target = conn['source'], conn['target']
            
            # å¯»æ‰¾ç°æœ‰ç»„
            found_group = None
            for group_id, group in te_groups.items():
                if source in group or target in group:
                    found_group = group_id
                    break
            
            if found_group is not None:
                te_groups[found_group].update([source, target])
            else:
                new_group_id = len(te_groups)
                te_groups[new_group_id] = {source, target}
        
        # æ·»åŠ TEç»„åˆ
        for group_id, group in te_groups.items():
            if len(group) >= 2:
                combinations.append({
                    'type': 'te_based',
                    'assets': list(group),
                    'size': len(group),
                    'strength': 'high' if len(group) >= 3 else 'medium'
                })
        
        return combinations
    
    def visualize_results(self, results: Dict, save_path: str = None):
        """å¯è§†åŒ–ç»“æœ"""
        try:
            logger.info("ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
            
            # è®¾ç½®å›¾å½¢æ ·å¼
            plt.style.use('seaborn-v0_8')
            fig = plt.figure(figsize=(20, 15))
            
            # 1. ç›¸å…³æ€§çƒ­åŠ›å›¾
            ax1 = plt.subplot(2, 3, 1)
            correlation_matrix = results.get('correlation_network', {}).get('correlation_matrix', self.price_data.corr())
            sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, ax=ax1)
            ax1.set_title('èµ„äº§ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
            ax1.set_xlabel('èµ„äº§')
            ax1.set_ylabel('èµ„äº§')
            
            # 2. ç½‘ç»œå›¾ï¼ˆå¦‚æœæœ‰ä¼ é€’ç†µç»“æœï¼‰
            ax2 = plt.subplot(2, 3, 2)
            if self.network_results:
                try:
                    plot_network(
                        results=self.network_results, 
                        weights="max_te_lag", 
                        fdr=False, 
                        ax=ax2
                    )
                    ax2.set_title('ä¼ é€’ç†µç½‘ç»œå›¾', fontsize=14, fontweight='bold')
                except Exception as e:
                    logger.warning(f"ç½‘ç»œå›¾ç»˜åˆ¶å¤±è´¥: {e}")
                    ax2.text(0.5, 0.5, 'ç½‘ç»œå›¾ä¸å¯ç”¨', ha='center', va='center', transform=ax2.transAxes)
                    ax2.set_title('ä¼ é€’ç†µç½‘ç»œå›¾ï¼ˆä¸å¯ç”¨ï¼‰', fontsize=14, fontweight='bold')
            else:
                ax2.text(0.5, 0.5, 'ç½‘ç»œå›¾ä¸å¯ç”¨', ha='center', va='center', transform=ax2.transAxes)
                ax2.set_title('ä¼ é€’ç†µç½‘ç»œå›¾ï¼ˆä¸å¯ç”¨ï¼‰', fontsize=14, fontweight='bold')
            
            # 3. é«˜ç›¸å…³èµ„äº§å¯¹
            ax3 = plt.subplot(2, 3, 3)
            if results.get('correlation_pairs'):
                pairs = results['correlation_pairs'][:10]  # å‰10ä¸ª
                assets = [f"{p['asset1']}-{p['asset2']}" for p in pairs]
                correlations = [p['correlation'] for p in pairs]
                
                bars = ax3.barh(assets, correlations, color='skyblue')
                ax3.set_xlabel('ç›¸å…³ç³»æ•°')
                ax3.set_title('é«˜ç›¸å…³èµ„äº§å¯¹ (Top 10)', fontsize=14, fontweight='bold')
                ax3.grid(True, alpha=0.3)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, bar in enumerate(bars):
                    width = bar.get_width()
                    ax3.text(width, bar.get_y() + bar.get_height()/2, 
                            f'{width:.3f}', ha='left', va='center')
            
            # 4. ä¼ é€’ç†µè¿æ¥
            ax4 = plt.subplot(2, 3, 4)
            if results.get('te_connections'):
                connections = results['te_connections'][:10]  # å‰10ä¸ª
                connections_str = [f"{c['source']}â†’{c['target']}" for c in connections]
                te_values = [c['transfer_entropy'] for c in connections]
                
                bars = ax4.barh(connections_str, te_values, color='lightcoral')
                ax4.set_xlabel('ä¼ é€’ç†µ')
                ax4.set_title('ä¼ é€’ç†µè¿æ¥ (Top 10)', fontsize=14, fontweight='bold')
                ax4.grid(True, alpha=0.3)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, bar in enumerate(bars):
                    width = bar.get_width()
                    ax4.text(width, bar.get_y() + bar.get_height()/2, 
                            f'{width:.3f}', ha='left', va='center')
            else:
                ax4.text(0.5, 0.5, 'æ— ä¼ é€’ç†µè¿æ¥', ha='center', va='center', transform=ax4.transAxes)
                ax4.set_title('ä¼ é€’ç†µè¿æ¥ï¼ˆæ— æ•°æ®ï¼‰', fontsize=14, fontweight='bold')
            
            # 5. èµ„äº§ç»„åˆåˆ†å¸ƒ
            ax5 = plt.subplot(2, 3, 5)
            if results.get('asset_combinations'):
                combinations = results['asset_combinations']
                types = [c['type'] for c in combinations]
                
                # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
                type_counts = {}
                for t in types:
                    type_counts[t] = type_counts.get(t, 0) + 1
                
                if type_counts:
                    ax5.pie(type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%')
                    ax5.set_title('èµ„äº§ç»„åˆç±»å‹åˆ†å¸ƒ', fontsize=14, fontweight='bold')
                else:
                    ax5.text(0.5, 0.5, 'æ— ç»„åˆæ•°æ®', ha='center', va='center', transform=ax5.transAxes)
                    ax5.set_title('èµ„äº§ç»„åˆç±»å‹åˆ†å¸ƒï¼ˆæ— æ•°æ®ï¼‰', fontsize=14, fontweight='bold')
            
            # 6. ç»„åˆå¤§å°åˆ†å¸ƒ
            ax6 = plt.subplot(2, 3, 6)
            if results.get('asset_combinations'):
                combinations = results['asset_combinations']
                sizes = [c['size'] for c in combinations]
                if sizes:
                    ax6.hist(sizes, bins=range(min(sizes), max(sizes)+2), 
                            alpha=0.7, color='lightgreen', edgecolor='black')
                    ax6.set_xlabel('ç»„åˆå¤§å°')
                    ax6.set_ylabel('é¢‘æ¬¡')
                    ax6.set_title('èµ„äº§ç»„åˆå¤§å°åˆ†å¸ƒ', fontsize=14, fontweight='bold')
                    ax6.grid(True, alpha=0.3)
                else:
                    ax6.text(0.5, 0.5, 'æ— ç»„åˆæ•°æ®', ha='center', va='center', transform=ax6.transAxes)
                    ax6.set_title('èµ„äº§ç»„åˆå¤§å°åˆ†å¸ƒï¼ˆæ— æ•°æ®ï¼‰', fontsize=14, fontweight='bold')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                logger.info(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
            
            plt.show()
            
        except Exception as e:
            logger.error(f"å¯è§†åŒ–å¤±è´¥: {e}")
    
    def generate_report(self, results: Dict, save_path: str = None) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        try:
            logger.info("ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            
            report = []
            report.append("# åŠ å¯†è´§å¸å¸‚åœºç½‘ç»œåˆ†ææŠ¥å‘Šï¼ˆæ— Javaç‰ˆæœ¬ï¼‰")
            report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report.append("")
            
            # æ•°æ®æ¦‚è§ˆ
            report.append("## æ•°æ®æ¦‚è§ˆ")
            report.append(f"- åˆ†æèµ„äº§æ•°é‡: {results['summary']['total_assets']}")
            report.append(f"- æ—¶é—´çª—å£: {self.config['time_hours']} å°æ—¶")
            report.append(f"- æ•°æ®ç‚¹æ•°é‡: {len(self.price_data)}")
            report.append(f"- ç½‘ç»œå¯†åº¦: {results['summary'].get('network_density', 0):.3f}")
            report.append("")
            
            # é«˜ç›¸å…³èµ„äº§å¯¹
            report.append("## é«˜åº¦ç›¸å…³èµ„äº§å¯¹")
            if results.get('correlation_pairs'):
                report.append(f"å‘ç° {len(results['correlation_pairs'])} ä¸ªé«˜åº¦ç›¸å…³çš„èµ„äº§å¯¹:")
                report.append("")
                for i, pair in enumerate(results['correlation_pairs'][:20], 1):
                    report.append(f"{i}. {pair['asset1']} â†” {pair['asset2']} (ç›¸å…³ç³»æ•°: {pair['correlation']:.4f})")
            else:
                report.append("æœªå‘ç°é«˜åº¦ç›¸å…³çš„èµ„äº§å¯¹")
            report.append("")
            
            # ä¼ é€’ç†µè¿æ¥
            report.append("## ä¼ é€’ç†µè¿æ¥")
            if results.get('te_connections'):
                report.append(f"å‘ç° {len(results['te_connections'])} ä¸ªä¼ é€’ç†µè¿æ¥:")
                report.append("")
                for i, conn in enumerate(results['te_connections'][:20], 1):
                    p_val_str = f" (på€¼: {conn['p_value']:.4f})" if conn['p_value'] else ""
                    report.append(f"{i}. {conn['source']} â†’ {conn['target']} (TE: {conn['transfer_entropy']:.4f}{p_val_str})")
            else:
                report.append("æœªå‘ç°æ˜¾è‘—çš„ä¼ é€’ç†µè¿æ¥")
            report.append("")
            
            # èµ„äº§ç»„åˆ
            report.append("## è¯†åˆ«å‡ºçš„èµ„äº§ç»„åˆ")
            if results.get('asset_combinations'):
                report.append(f"å‘ç° {len(results['asset_combinations'])} ä¸ªèµ„äº§ç»„åˆ:")
                report.append("")
                for i, combo in enumerate(results['asset_combinations'], 1):
                    report.append(f"{i}. {combo['type']} ç»„åˆ: {', '.join(combo['assets'])} (å¤§å°: {combo['size']}, å¼ºåº¦: {combo['strength']})")
            else:
                report.append("æœªå‘ç°æ˜¾è‘—çš„èµ„äº§ç»„åˆ")
            report.append("")
            
            # æŠ€æœ¯è¯´æ˜
            report.append("## æŠ€æœ¯è¯´æ˜")
            report.append("æœ¬åˆ†æä½¿ç”¨PythonåŸç”Ÿä¼°è®¡å™¨ï¼Œæ— éœ€Javaç¯å¢ƒï¼š")
            report.append(f"- ä¼°è®¡å™¨ç±»å‹: {self.config['cmi_estimator']}")
            report.append(f"- Kraskovå‚æ•°k: {self.config['kraskov_k']}")
            report.append(f"- çº¿ç¨‹æ•°: {self.config['num_threads']}")
            report.append(f"- ç½®æ¢æ¬¡æ•°: {self.config['n_perm_max_stat']}")
            report.append("")
            
            # æŠ•èµ„å»ºè®®
            report.append("## æŠ•èµ„å»ºè®®")
            report.append("åŸºäºç½‘ç»œåˆ†æç»“æœï¼Œå»ºè®®å…³æ³¨ä»¥ä¸‹æ–¹é¢:")
            report.append("")
            report.append("1. **é«˜ç›¸å…³èµ„äº§**: è¿™äº›èµ„äº§ä»·æ ¼å˜åŠ¨é«˜åº¦åŒæ­¥ï¼Œé€‚åˆé…å¯¹äº¤æ˜“ç­–ç•¥")
            report.append("2. **ä¼ é€’ç†µè¿æ¥**: è¿™äº›è¿æ¥æ˜¾ç¤ºäº†ä¿¡æ¯æµåŠ¨æ–¹å‘ï¼Œå¯ç”¨äºé¢„æµ‹ä»·æ ¼å˜åŠ¨")
            report.append("3. **èµ„äº§ç»„åˆ**: è¿™äº›ç»„åˆå¯ä»¥ä½œä¸ºæŠ•èµ„ç»„åˆæ„å»ºçš„å‚è€ƒ")
            report.append("")
            report.append("**é£é™©æç¤º**: æœ¬åˆ†æåŸºäºå†å²æ•°æ®ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ï¼Œè¯·è°¨æ…æŠ•èµ„ã€‚")
            
            # ä¿å­˜æŠ¥å‘Š
            report_text = "\n".join(report)
            if save_path:
                with open(save_path, 'w', encoding='utf-8') as f:
                    f.write(report_text)
                logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}")
            
            return report_text
            
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åŠ å¯†è´§å¸å¸‚åœºç½‘ç»œåˆ†æç³»ç»Ÿï¼ˆæ— Javaç‰ˆæœ¬ï¼‰")
    print("=" * 50)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = CryptoNetworkAnalyzerNoJava()
    
    # è·å–å’Œé¢„å¤„ç†æ•°æ®
    print("ğŸ“Š æ­£åœ¨è·å–å’Œé¢„å¤„ç†æ•°æ®...")
    if not analyzer.fetch_and_preprocess_data():
        print("âŒ æ•°æ®è·å–å¤±è´¥")
        return
    
    # æ‰§è¡Œç½‘ç»œåˆ†æ
    print("ğŸ” æ­£åœ¨æ‰§è¡Œç½‘ç»œåˆ†æ...")
    if not analyzer.analyze_network():
        print("âŒ ç½‘ç»œåˆ†æå¤±è´¥")
        return
    
    # è¯†åˆ«é«˜åº¦å…³è”çš„èµ„äº§
    print("ğŸ¯ æ­£åœ¨è¯†åˆ«é«˜åº¦å…³è”çš„èµ„äº§ç»„åˆ...")
    results = analyzer.identify_highly_correlated_assets()
    
    if not results:
        print("âŒ èµ„äº§è¯†åˆ«å¤±è´¥")
        return
    
    # ç”Ÿæˆå¯è§†åŒ–
    print("ğŸ“ˆ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    analyzer.visualize_results(results, 'crypto_network_analysis_no_java.png')
    
    # ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“ æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report = analyzer.generate_report(results, 'crypto_network_report_no_java.md')
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "=" * 50)
    print("ğŸ“Š åˆ†æå®Œæˆï¼")
    print(f"âœ… åˆ†æäº† {results['summary']['total_assets']} ä¸ªèµ„äº§")
    print(f"âœ… å‘ç° {results['summary']['highly_correlated_pairs']} ä¸ªé«˜ç›¸å…³å¯¹")
    print(f"âœ… å‘ç° {results['summary']['te_connections']} ä¸ªä¼ é€’ç†µè¿æ¥")
    print(f"âœ… è¯†åˆ«å‡º {results['summary']['asset_combinations']} ä¸ªèµ„äº§ç»„åˆ")
    print(f"âœ… ç½‘ç»œå¯†åº¦: {results['summary'].get('network_density', 0):.3f}")
    print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print("- crypto_network_analysis_no_java.png (å¯è§†åŒ–å›¾è¡¨)")
    print("- crypto_network_report_no_java.md (åˆ†ææŠ¥å‘Š)")
    print("- crypto_network_analysis_no_java.log (æ—¥å¿—æ–‡ä»¶)")


if __name__ == "__main__":
    main()